{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkBAUsSy_Cuy",
        "outputId": "efeb7172-28ab-4f34-d31b-24b11a0ac70c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-jt5My6s_PND",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "ad7e6ba9-bffa-4303-8e63-f93c850e7aac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://7aea07f4f1f6:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "sc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(1,11,2),(1,11,3),(2,11,3),(3,11,2),(3,11,4),(4,11,1),(4,11,2),(4,11,3),(4,12,5),(5,12,1),(5,12,2),(5,12,6)]"
      ],
      "metadata": {
        "id": "U2Ex5QXrRIem"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parte 1**"
      ],
      "metadata": {
        "id": "W2kU7ryyPCla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 Precalentamiento: Triángulos.\n",
        "\n"
      ],
      "metadata": {
        "id": "egeWCWGCPHDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fase de Map.**\n",
        "\n",
        "Cada mapper tendra una cierta cantidad de aristas del grafo. Para cada arista (n1, R, n2),\n",
        "el mapper debe hacer lo siguiente.\n",
        "\n",
        "1. Hashear los nodos: b1 = h(n1), b2 = h(n2).\n",
        "2. Como el triangulo que formemos solo puede mapear la variable x a n1 e y a n2, la arista (n1, R, n2)\n",
        "solo podrıa formar parte de un trıangulo de la forma (n1, n2, a) para un a ∈V . Entonces, generamos b\n",
        "llaves (b1, b2, 0), . . . , (b1, b2, b −1), y emitimos b mensajes con el contenido de la arista, uno para cada\n",
        "llave: ((b1, b2, 0), (n1, R, n2)), . . . , ((b1, b2, b −1), (n1, R, n2))"
      ],
      "metadata": {
        "id": "svN3U-UkoVdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la primera parte, realizaremos un una función que permita hashear de la forma (key, arista)"
      ],
      "metadata": {
        "id": "pAZC9GMGRCO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def key_edge(edge):\n",
        "  map = [] # Lista que contiene los pares key, arista para una determinada edge\n",
        "  b1, label, b2 = edge # Descomponemos la arista entregada\n",
        "  for i in range (2): #Iteramos en los valores de mod 2: 0,1\n",
        "    map.append(((b1%2, b1%2, i), edge)) #agregamos los pares ((b1, b2, 0), (n1, R, n2)), . . . , ((b1, b2, b −1), (n1, R, n2))\n",
        "  return map\n",
        "\n"
      ],
      "metadata": {
        "id": "t-qvJW2SPtg1"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize(data)\n",
        "rdd.flatMap(key_edge).collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkUHeqkhRBNT",
        "outputId": "fb936925-1738-4f1e-9248-d47b78e2a5f3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((1, 1, 0), (1, 11, 2)),\n",
              " ((1, 1, 1), (1, 11, 2)),\n",
              " ((1, 1, 0), (1, 11, 3)),\n",
              " ((1, 1, 1), (1, 11, 3)),\n",
              " ((0, 0, 0), (2, 11, 3)),\n",
              " ((0, 0, 1), (2, 11, 3)),\n",
              " ((1, 1, 0), (3, 11, 2)),\n",
              " ((1, 1, 1), (3, 11, 2)),\n",
              " ((1, 1, 0), (3, 11, 4)),\n",
              " ((1, 1, 1), (3, 11, 4)),\n",
              " ((0, 0, 0), (4, 11, 1)),\n",
              " ((0, 0, 1), (4, 11, 1)),\n",
              " ((0, 0, 0), (4, 11, 2)),\n",
              " ((0, 0, 1), (4, 11, 2)),\n",
              " ((0, 0, 0), (4, 11, 3)),\n",
              " ((0, 0, 1), (4, 11, 3)),\n",
              " ((0, 0, 0), (4, 12, 5)),\n",
              " ((0, 0, 1), (4, 12, 5)),\n",
              " ((1, 1, 0), (5, 12, 1)),\n",
              " ((1, 1, 1), (5, 12, 1)),\n",
              " ((1, 1, 0), (5, 12, 2)),\n",
              " ((1, 1, 1), (5, 12, 2)),\n",
              " ((1, 1, 0), (5, 12, 6)),\n",
              " ((1, 1, 1), (5, 12, 6))]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fase de Reduce.**\n",
        "\n",
        " Los reducers reciben siempre los mensajes correspondientes a alguna llave (b1, b2, b3).\n",
        "Pero en el valor de esa llave se encuentran aristas. Todas estas aristas forman un pequeño grafo , y el reducer\n",
        "emite como respuesta todas las tuplas (n1, n2, n3) correspondientes a los triangulos que detecta en su grafo"
      ],
      "metadata": {
        "id": "hUg_FTIydUpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def triangles(key, edge):\n",
        "  pass\n"
      ],
      "metadata": {
        "id": "S-dXgWhycSeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "seJEkhMtfBRD"
      },
      "execution_count": 39,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}