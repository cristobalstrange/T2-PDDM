{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkBAUsSy_Cuy",
        "outputId": "1f275be0-ca9c-48af-eb59-0833bb2fdb3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=f229ce40d7f898400f8498ae31f886f586780d4c59b16d6e2222ced82e713fa6\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "-jt5My6s_PND",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "adb88259-26fc-4b18-c5cc-c5c25a4daf99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://02c6a4d409c8:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "sc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (1,11,2),(1,11,3),(2,11,3),\n",
        "    (3,11,2),(3,11,4),(4,11,1),\n",
        "    (4,11,2),(4,11,3),(4,12,5),\n",
        "    (5,12,1),(5,12,2),(5,12,6)\n",
        "    ]"
      ],
      "metadata": {
        "id": "U2Ex5QXrRIem"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parte 1**"
      ],
      "metadata": {
        "id": "W2kU7ryyPCla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 Precalentamiento: Triángulos.\n",
        "\n"
      ],
      "metadata": {
        "id": "egeWCWGCPHDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fase de Map.**\n",
        "\n",
        "Cada mapper tendra una cierta cantidad de aristas del grafo. Para cada arista (n1, R, n2),\n",
        "el mapper debe hacer lo siguiente.\n",
        "\n",
        "1. Hashear los nodos: b1 = h(n1), b2 = h(n2).\n",
        "2. Como el triangulo que formemos solo puede mapear la variable x a n1 e y a n2, la arista (n1, R, n2)\n",
        "solo podrıa formar parte de un trıangulo de la forma (n1, n2, a) para un a ∈V . Entonces, generamos b\n",
        "llaves (b1, b2, 0), . . . , (b1, b2, b −1), y emitimos b mensajes con el contenido de la arista, uno para cada\n",
        "llave: ((b1, b2, 0), (n1, R, n2)), . . . , ((b1, b2, b −1), (n1, R, n2))"
      ],
      "metadata": {
        "id": "svN3U-UkoVdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la primera parte, realizaremos un una función que permita hashear de la forma (key, arista)"
      ],
      "metadata": {
        "id": "pAZC9GMGRCO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def key_edge(edge, b):\n",
        "  map = [] # Lista que contiene los pares key, arista para una determinada edge\n",
        "  n1, label, n2 = edge # Descomponemos la arista entregada\n",
        "  for i in range (b): #Iteramos en los valores de mod 2: 0,1\n",
        "    map.append(((n1%b, n2%b, i), edge)) #agregamos los pares ((b1, b2, 0), (n1, R, n2)), . . . , ((b1, b2, b −1), (n1, R, n2))\n",
        "  return map\n",
        "\n"
      ],
      "metadata": {
        "id": "t-qvJW2SPtg1"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Probamos para Triangulos (X,11,Y), (Y,11,Z), (Z,11,X)**"
      ],
      "metadata": {
        "id": "9jAYKhEqQd2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_triangles = [edge for edge in data if edge[1] == 11]\n",
        "\n",
        "rdd = sc.parallelize(data_triangles)\n",
        "rdd.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkUHeqkhRBNT",
        "outputId": "5c56ca51-f3cf-49c3-d1bd-c467ecd1e692"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 11, 2),\n",
              " (1, 11, 3),\n",
              " (2, 11, 3),\n",
              " (3, 11, 2),\n",
              " (3, 11, 4),\n",
              " (4, 11, 1),\n",
              " (4, 11, 2),\n",
              " (4, 11, 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "map_rdd = rdd.flatMap(lambda x: key_edge(x, 2))\n",
        "map_rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SztVh73D0Ys",
        "outputId": "6c10293e-e494-411a-fce8-edaa39fdce42"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((1, 0, 0), (1, 11, 2)),\n",
              " ((1, 0, 1), (1, 11, 2)),\n",
              " ((1, 1, 0), (1, 11, 3)),\n",
              " ((1, 1, 1), (1, 11, 3)),\n",
              " ((0, 1, 0), (2, 11, 3)),\n",
              " ((0, 1, 1), (2, 11, 3)),\n",
              " ((1, 0, 0), (3, 11, 2)),\n",
              " ((1, 0, 1), (3, 11, 2)),\n",
              " ((1, 0, 0), (3, 11, 4)),\n",
              " ((1, 0, 1), (3, 11, 4)),\n",
              " ((0, 1, 0), (4, 11, 1)),\n",
              " ((0, 1, 1), (4, 11, 1)),\n",
              " ((0, 0, 0), (4, 11, 2)),\n",
              " ((0, 0, 1), (4, 11, 2)),\n",
              " ((0, 1, 0), (4, 11, 3)),\n",
              " ((0, 1, 1), (4, 11, 3))]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fase de Reduce.**\n",
        "\n",
        " Los reducers reciben siempre los mensajes correspondientes a alguna llave (b1, b2, b3).\n",
        "Pero en el valor de esa llave se encuentran aristas. Todas estas aristas forman un pequeño grafo , y el reducer\n",
        "emite como respuesta todas las tuplas (n1, n2, n3) correspondientes a los triangulos que detecta en su grafo"
      ],
      "metadata": {
        "id": "hUg_FTIydUpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "group_rdd = map_rdd.groupByKey().mapValues(list)\n",
        "group_rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "revxsn6FBOwP",
        "outputId": "8bbd6e96-45b6-4d9a-d164-30f7c77e397d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((1, 0, 0), [(1, 11, 2), (3, 11, 2), (3, 11, 4)]),\n",
              " ((1, 1, 1), [(1, 11, 3)]),\n",
              " ((0, 1, 0), [(2, 11, 3), (4, 11, 1), (4, 11, 3)]),\n",
              " ((0, 0, 1), [(4, 11, 2)]),\n",
              " ((1, 0, 1), [(1, 11, 2), (3, 11, 2), (3, 11, 4)]),\n",
              " ((1, 1, 0), [(1, 11, 3)]),\n",
              " ((0, 1, 1), [(2, 11, 3), (4, 11, 1), (4, 11, 3)]),\n",
              " ((0, 0, 0), [(4, 11, 2)])]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reducer**"
      ],
      "metadata": {
        "id": "ZwjZ8rU2TWoM"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}